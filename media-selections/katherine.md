## Name
Github Username:katherineweinschenk

Field of Study, Year: CS and Anthropology - 3rd Year

> I'm taking this class because I think that computer scientists are trained for efficiency, not ethics. I want to learn the adverse effects of technology so I don't contribute to the problem and so I can advocate for more critical thinking in the field.


### Class 1 - Content Moderation (free speech restrictions) on the Internet

[YouTube’s arbitrary standards: Stars keep making money even after breaking the rules](https://www.washingtonpost.com/technology/2019/08/09/youtubes-arbitrary-standards-stars-keep-making-money-even-after-breaking-rules/?noredirect=on)

Media Justification: This week's topic reminded me of the Logan Paul Youtube scandal from this past year, so I looked for an article about it. This Washington Post article details the perspective of moderators at Youtube who have noticed Youtube's unfair content moderation rules. It explains that the lack of equality mostly surrounds issues with money and advertising: the main things that social media platforms are concerned with. One moderator wrote “Our responsibility was never to the creators or to the users — it was to the advertisers" - which should have been included in the list of problems with content moderation article. 

### Class 2 - Algorithmic Bias

[AI-powered cameras become new tool against mass shootings](https://www.latimes.com/business/story/2019-09-04/ai-powered-cameras-become-new-tool-against-mass-shootings)

Media Justification: This article, to me, is so ridiculous. We have resorted to artificial intelligence, which is just a lot of matrix math, to identify and "stop" school shooters. "Intelligent video" is supposed to be able to identify not only weapons, but "violent" facial expressions. I'm not sure what this even means, and overall, it's avoiding the main issue, which is that Americans have very easy access to guns. Also, data-driven racism could make this technology go horribly wrong. For some reason, we really have trouble identifying the root cause of problems, and at the same time put so much trust in non-sentient bodies (computers and guns!).

### Class 3 - Regulating Tech Monopolies

[Adam Ruins Everything - How the Government Created Tech Monopolies | truTV](https://www.youtube.com/watch?v=mid1VvK9Xpgs)

[Please Regulate Us: Tech Firms Need More Regulation](https://www.theatlantic.com/ideas/archive/2019/09/please-regulate-us/597613/)

This short Adam Ruins Everything clip reveals a small part of the relationship between government and tech companies that I have never really considered. The concept that tech companies exist outside of the public sphere is false; according to this video, the US government invested $4.5 million in Google and a half a billion dollars in Tesla to help them begin. Despite this, Adam points out that these companies don't pay the taxes they should, and therefore have a less reciprocal relationship with the govenment. In the Atlantic article, the author (president of Microsoft, Brad Smith), points out that "Many in tech circles have asserted that people in government don’t understand enough about technology to regulate it properly—even while tech companies have benefited from all manner of government funding and support." In my opinion, by accepting government funding, you acknowledge that you have an obligation to the government. The government should be expected to regulate these companies as they are not separate actors. On another note, it's interesting that the President of Microsoft wrote this article, but it makes sense at the end of the article. He ends with the statement, "Technology innovation is not going to slow down. The work to manage it needs to speed up," placing the responsibility on regulators, rather than innovators.

### Class 4 - Anonymity 

[Google wins case over EU’s ‘right to be forgotten’ rules](https://www.washingtonpost.com/world/europe/eu-top-court-rules-in-favor-of-google-on-search-engine-issue/2019/09/24/aeb78c9e-dea4-11e9-be7f-4cc85017c36f_story.html)

This seems like the most relevant topic to discuss, considering that the EU's highest court ruled only two days ago that the "right to be forgotten" rule does not apply outside of the EU. This means that people cannot request for their information to be removed beyond the internet in the EU (which seems a little arbitrary to me). However, the court also ruled that search engines must discourage internet users from going outside of the EU to find the deleted information from inside the EU. This relates to our conversation about how to deal with a "borderless" internet in a heavily bordered world. 



### Class 5 - Data Ownership and Privacy

[DATA AS A PROPERTY RIGHT](https://www.yang2020.com/policies/data-property-right/)

After some research, I came across Andrew Yang's 7 points for implementing data regulations. He, too, describes data in terms of ownership and encourages individual ownership of data. His proposed "rights" reflect ideas that are present in the GDRP, such as the right to be forgotten. These rights also include the right to be informed if the ownership of your data changes hands, the right to be told how a website uses your data, etc. What interests me is his concluding paragraph in which he mentions the ideas of informed consent and just compensation. As academic researchers are held to these ethical standards, corporate researchers should only be allowed to evaluate data if it is collected with informed consent, and if the research subjects are compensated (in Yang's terms, monetarily) for their data/information.

### Class 6 - Surveillance Capitalism

[Here are 4 steps to defend yourself from Big Tech’s greed-driven behavioral manipulation](https://www.alternet.org/2019/09/here-are-4-steps-to-defend-yourself-from-big-techs-greed-driven-behavioral-manipulation/)

This article references Zuboff's book and responds to it by proposing 4 ways to avoid companies' behavioral manipulation. The four points are: 1) join the resistance, 2) minimize your interaction with technology, 3) do less phone-orientation activities, and 4) join an activist group. I thought this was interesting because Zuboff did not propose solutions to surveillance capitalism, but rather sought to define it. However, I don't agree with the simplicity of this article's answers. The article suggests that it is the individual's obligation to protect themself from exploitation and manipulation, which does nothing to dismantle the system but places more anxiety on the individual. These technologies that have been adopted for surveillance capitalism have been designed to create dependency, and it should be the duty of the owners of surveillance capital not manipulate. At the same time, I understand that if one is feeling frustrated/helpless against this beast, it could be easier to withdraw from participation than to propose and fight for reform.



### Class 7 - Social Media and Democracy

[CSPAN on Twitter](https://twitter.com/cspan/status/1187098428737753091?s=20)

I love the energy AOC has during this questioning. She is unafraid to call Zuckerburg out on certain things - "in your ongoing dinner parties with far right figures..." - making him uncomfortable with what we all are already uncomfortable. It's interesting that his response to the question of taking content down is "yes, if it causes violence, harm, or voter supression," just tacking on the main issue at the end as if he's trying to mask his answer. I especially liked "I think lying is bad"; he's being condescending about morality and placing the job of fact-checking on individuals, while placing the blame of lying on those who spread disinformation instead of his company for propogating it. I think the topic of free speech is fascinating in this context. We need to redefine what free speech is and what safety is to maintain a democracy.


### Class 8 - Bad Gov Tech and Its Consequences

[Digital dystopia: how algorithms punish the poor ](https://www.theguardian.com/technology/2019/oct/14/automating-poverty-algorithms-punish-poor)

The reading this week had to do with how automation disparately affects poor and underprivileged people. I found a similarly themed article from The Guardian that explores this concept further, extending its analysis outside of the US, too. It notes that the trend towards automation is "explosively recasting how low-income people interact with the state." It also explains how shifting the responsibility of decision making to an algorithm places accountability on a nonhuman actor, making it difficult to blame for errors and making it difficult to seek redress. This is especially dangerous for people without the resources to fight these changes, and it will allow systematic forms of oppression to proceed unchecked. 


### Class 9 - Digital Discourse

[Reconsidering Anonymity in the Age of Narcissism](https://gabriellacoleman.org/wp-content/uploads/2019/09/Coleman-end-trust-anonymity.pdf)

This week's VICE video made me think more about the pros and cons of anonymity on the internet. It was a disturbing video that reminded me that anonymity has the potential to create unthinkably dark spaces such as 8chan. However, while scrolling through twitter, I came across an essay written by Gabriella Coleman about how anonymity can enable democratic processes like dissent and provide safe/protected spaces for discussing stigmatized subjects. She discusses different gradients of anonymity (like using a psuedonym and choosing an obscure avatar icon or concealing IP address). She also provides a thoughtful analysis on misinformation and how it spreads due to factors beyond anonymity. I'm not going to rewrite her whole article, but I think that it's an important essay to read.

### Class 10 - Current Tech Policy

[Court Upholds Net Neutrality Repeal, With Some Caveats](https://www.nytimes.com/2019/10/01/technology/net-neutrality-repeal-broadband.html)

To me, net neutrality feels like one of our less important problems. I don't feel much of a moral obligation to the cause, and ambiguous rulings like the one described in this article leaves me confused. The article states that while a federal appeals court upheld the repeal of strict regulations, it also ruled that the FCC overstepped their power into state and local government rules. So, while we have moved toward deregulation, states like California (who is currently trying to) will have the ability to impose its own regulations. I just think this issue is a product of capitalism, again, and our disjointed government system. 


