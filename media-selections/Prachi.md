Prachi Sadekar

psadekar

Systems Engineering, 1st Year

I am taking this class because I am interested in how the growth of technology and our increasing dependence on it can (or cannot) be regulated by government policy. 


### Class 1 - Content Moderation on the Internet

[Is Social Media Content Moderation Impossible](https://www.forbes.com/sites/kalevleetaru/2018/09/08/is-social-media-content-moderation-an-impossible-task/#45957d115fa8)

Media Justification: This article relates to the week’s topic of content moderation and free speech because it discusses the difficulty of establishing a common set of rules for moderation of online content in a global setting. Because social media sites and other online platforms operate worldwide, the content they curate must be deemed socially and culturally acceptable in all countries – a great challenge because many eastern countries have not adopted the western beliefs of free speech. The article also touches on how even if a post is taken down from its country of origin, it can still be accessed through sites such as Wikileaks and never truly disappears online. 

### Class 2 - Algorithmic Bias

[TED Institute - Can we protect AI from our biases?](https://www.youtube.com/watch?v=eV_tx4ngVT0)

Media Justification: This video from TED institute discusses how humans are inherently biased (can be good or bad) and how our biases translate into algorithms unconsciously. Robin Hauser, the speaker, mentions examples of AI that were left to learn from biased online sources such as Twitter (Microsoft’s TayTweets) and Urban Dictionary (IBM’s Watson) and within a few hours the machines also echoed those views. The media selection relates to this week’s topic of algorithmic bias because it highlights the ways our own biases seep into programs and warns that we must combat the issue now before it’s too late for the AI to unlearn it. 

### Class 3 - Regulating Tech Monopolies

[Breaking the Monopolies of Facebook, Google, and Amazon](https://www.youtube.com/watch?v=k4m-phHynmE)

Media Justification: This TedxTalk by Kat Chrysostom discusses the dangers of tech monopolies like Facebook, Google, and Amazon having complete access to users' data. As she started her speech, Chrysostom gave an example of how she tracked the third-party companies watching her online data without permission as she used Google and found over 150 companies following her as she moved through her email and a news article. She goes on to note that Facebook and Google own 78% market share of the digital advertising market in the U.S., and the only company making any significant changes to their market-cap is Amazon. This video relates to this week's topic of regulating tech monopolies because it highlights the dangers of having a few companies control the majority of user data and offers solutions, such as passing laws to make data private to the user and giving them the ability to sell it to companies, to fixing the rising concern of tech monopolies.


### Class 4 - Anonymity and the Right to be Forgotten

[European Court’s Decision in Right To Be Forgotten Case is a Win for Free Speech](https://www.eff.org/deeplinks/2019/09/european-courts-decision-right-be-forgotten-case-win-free-s)

Media Justification: This article in the Electronic Frontier Foundation talks about the implications of the recent ruling (Tuesday) in the Court of Justice in the European Union. It was established that Google was only required to erase access to articles within the EU, not globally, when individuals ask the browser to take down their information for privacy reasons. In the ruling, the court wrote that it would not prohibit Google from taking down information globally in extraordinary circumstances, leaving the door open for further discussion on the matter. This article relates to this week's topic of anonymity and the right to be fogotten because it details the implications of the Right to be Forgotten regulation in the EU and how the restrictive policy cannot be applied worldwide because of the differing privacy and information laws in countries around the world.

### Class 5 - Data Ownership and Privacy

[You can now make money selling your own health data, but should you?](https://www.fastcompany.com/90409942/would-you-sell-your-own-health-data-theres-a-market-for-it-but-ethical-concerns-remain)

Media Justification: This article talks about the consequences of selling/sharing your health data, even willingly, and how it can affect privacy until death. Medical data, unlike physical property, can be sold an unlimited number of times without diminishing in value, and this aspect of data is what makes it dangerous for the public to sell. A company called Hu-manity.co created a platform to link data collectors and users who want to sell their medical data. The platform is under scrutiny by the ACLU because the civil rights organization believes that the platform is exploiting an uninformed public into selling their data for vastly undervalued prices. Another debate the article brings up is that of selling genomic data, or one's DNA. DNA information is more of a privacy risk than medical information because genes are shared through family, so if one member decides to sell his data, companies now have access to many of the genes of the family. I think this article is important in the discussion of data ownership and privacy because with new medical technologies on the rise, having privacy over medical information is crucial.

### Class 6 - Surveillance Capitalism

[How facial recognition technology is bringing surveillance capitalism to our streets](https://www.opendemocracy.net/en/oureconomy/how-facial-recognition-surveillance-capitalism-streets/)

Media Justification: This article discusses the impact of our right to privacy in a world where facial recognition technology, combined with data collection online, leaves no personal information anonymous. In Kings Cross, London, two biometric scanners were placed within a privately owned but very public space. The technology was supplemented by the Police Department's records, so the company had information on people walking through the area who had a file in the police records. Similarly, an app called FindFace (no longer publicly available) gave the user the ability to find a person's social media accounts with simply a picture of their face. This kind of recognition technology is problematic not only in its security concerns, but when combined with information found through online suveillance, big data companies will have knowledge of a person's location, tastes/interests, friends/family, and other private information. Merchandising companies in the areas where (hypothetical) biometric scanners are placed would have the information to change their advertising to match the public walking through the area based on the time and day. This article is relevant to this week's topic of Surveillance Capitalism because it brings to light another consequence of technology companies having our private information, especially as recognition software becomes more accurate. 
