Prachi Sadekar

psadekar

Systems Engineering, 1st Year

I am taking this class because I am interested in how the growth of technology and our increasing dependence on it can (or cannot) be regulated by government policy. 


### Class 1 - Content Moderation on the Internet

[Is Social Media Content Moderation Impossible](https://www.forbes.com/sites/kalevleetaru/2018/09/08/is-social-media-content-moderation-an-impossible-task/#45957d115fa8)

Media Justification: This article relates to the week’s topic of content moderation and free speech because it discusses the difficulty of establishing a common set of rules for moderation of online content in a global setting. Because social media sites and other online platforms operate worldwide, the content they curate must be deemed socially and culturally acceptable in all countries – a great challenge because many eastern countries have not adopted the western beliefs of free speech. The article also touches on how even if a post is taken down from its country of origin, it can still be accessed through sites such as Wikileaks and never truly disappears online. 

### Class 2 - Algorithmic Bias

[TED Institute - Can we protect AI from our biases?](https://www.youtube.com/watch?v=eV_tx4ngVT0)

Media Justification: This video from TED institute discusses how humans are inherently biased (can be good or bad) and how our biases translate into algorithms unconsciously. Robin Hauser, the speaker, mentions examples of AI that were left to learn from biased online sources such as Twitter (Microsoft’s TayTweets) and Urban Dictionary (IBM’s Watson) and within a few hours the machines also echoed those views. The media selection relates to this week’s topic of algorithmic bias because it highlights the ways our own biases seep into programs and warns that we must combat the issue now before it’s too late for the AI to unlearn it. 

### Class 3 - Regulating Tech Monopolies

[Breaking the Monopolies of Facebook, Google, and Amazon](https://www.youtube.com/watch?v=k4m-phHynmE)

Media Justification: This TedxTalk by Kat Chrysostom discusses the dangers of tech monopolies like Facebook, Google, and Amazon having complete access to users' data. As she started her speech, Chrysostom gave an example of how she tracked the third-party companies watching her online data without permission as she used Google and found over 150 companies following her as she moved through her email and a news article. She goes on to note that Facebook and Google own 78% market share of the digital advertising market in the U.S., and the only company making any significant changes to their market-cap is Amazon. This video relates to this week's topic of regulating tech monopolies because it highlights the dangers of having a few companies control the majority of user data and offers solutions, such as passing laws to make data private to the user and giving them the ability to sell it to companies, to fixing the rising concern of tech monopolies.


### Class 4 - Anonymity and the Right to be Forgotten

[European Court’s Decision in Right To Be Forgotten Case is a Win for Free Speech](https://www.eff.org/deeplinks/2019/09/european-courts-decision-right-be-forgotten-case-win-free-s)

Media Justification: This article in the Electronic Frontier Foundation talks about the implications of the recent ruling (Tuesday) in the Court of Justice in the European Union. It was established that Google was only required to erase access to articles within the EU, not globally, when individuals ask the browser to take down their information for privacy reasons. In the ruling, the court wrote that it would not prohibit Google from taking down information globally in extraordinary circumstances, leaving the door open for further discussion on the matter. This article relates to this week's topic of anonymity and the right to be fogotten because it details the implications of the Right to be Forgotten regulation in the EU and how the restrictive policy cannot be applied worldwide because of the differing privacy and information laws in countries around the world.

### Class 5 - Data Ownership and Privacy

[You can now make money selling your own health data, but should you?](https://www.fastcompany.com/90409942/would-you-sell-your-own-health-data-theres-a-market-for-it-but-ethical-concerns-remain)

Media Justification: This article talks about the consequences of selling/sharing your health data, even willingly, and how it can affect privacy until death. Medical data, unlike physical property, can be sold an unlimited number of times without diminishing in value, and this aspect of data is what makes it dangerous for the public to sell. A company called Hu-manity.co created a platform to link data collectors and users who want to sell their medical data. The platform is under scrutiny by the ACLU because the civil rights organization believes that the platform is exploiting an uninformed public into selling their data for vastly undervalued prices. Another debate the article brings up is that of selling genomic data, or one's DNA. DNA information is more of a privacy risk than medical information because genes are shared through family, so if one member decides to sell his data, companies now have access to many of the genes of the family. I think this article is important in the discussion of data ownership and privacy because with new medical technologies on the rise, having privacy over medical information is crucial.

### Class 7 - Surveillance Capitalism

[How facial recognition technology is bringing surveillance capitalism to our streets](https://www.opendemocracy.net/en/oureconomy/how-facial-recognition-surveillance-capitalism-streets/)

Media Justification: This article discusses the impact of our right to privacy in a world where facial recognition technology, combined with data collection online, leaves no personal information anonymous. In Kings Cross, London, two biometric scanners were placed within a privately owned but very public space. The technology was supplemented by the Police Department's records, so the company had information on people walking through the area who had a file in the police records. Similarly, an app called FindFace (no longer publicly available) gave the user the ability to find a person's social media accounts with simply a picture of their face. This kind of recognition technology is problematic not only in its security concerns, but when combined with information found through online suveillance, big data companies will have knowledge of a person's location, tastes/interests, friends/family, and other private information. Merchandising companies in the areas where (hypothetical) biometric scanners are placed would have the information to change their advertising to match the public walking through the area based on the time and day. This article is relevant to this week's topic of Surveillance Capitalism because it brings to light another consequence of technology companies having our private information, especially as recognition software becomes more accurate. 

### Class 8 - Bad Gov Tech & Its Consequences

[UK Department for Work and Pensions accelerates use of robots](https://www.globalgovernmentforum.com/uk-department-for-work-and-pensions-accelerates-use-of-robots/)

Media Justification: This article talks about automating the welfare claims of citizens in the UK by implementing artificial intelligence that decides whether an applicant's housing and childcare costs are true or not. Similarly to the system in Indiana (from the Automating Inequality Chapter), claimants are left at the mercy of the algorithm, and significant problems with the system have already been raised. The goal of automation was for employees in welfare services to have more time to help especially disadvantaged citizens through their claims, but in reality, the algorithm does not allow for compassion and employees have already stopped contradicting the decisions the algorithm makes. This article expands on and offers another example of the consequences with implementing automated systems to make welfare decisions for citizens that are already disadvantaged. 

### Class 9 - Social Media & Democracy

[How Social Media is Shaping Our Political Future](https://www.youtube.com/watch?v=9Kd99IIWJUw)

Media Justification: This Ted Talk by Victoria Bonney discusses the more positive impacts that social media platforms have created within out democracy. She argues that before social media, candidates for office (generally for a federal level) had to have a high level degree, come from a wealthy family, and be male - characteristics that many Americans could not relate to. Social media platforms give less wealthy candidates the chance to create a voter base through their ideals, not their backgrounds. Also, Bonney argues that typically marginalized people now have a voice through social media, and citizens now have a direct line of communication to their representatives. I thought this was an appropriate media selecion for this week because when we usually consider the impact of social media on democracy, we think of the impact of "Fake News" or polarization of the political sides. The video brings to light the positive effects the social media can have, when used appropriately, on American democracy. 

### Class 10 - Digital Discourse
[Instagram Will Test Hiding 'Likes' in the US Starting Next Week](https://www.wired.com/story/instagram-hiding-likes-adam-mosseri-tracee-ellis-ross-wired25/#intcid=recommendations_wired-right-rail-popular_1a0f6a5b-b4b0-4287-af1b-6369d6cdb6fb_cral-top3-1)

Media Justification: This article in WIRED describes Instagram CEO, Adam Mosseri's, efforts to make Instagram a platform in which happy and healthy online discourse can take place. To facilitate this, starting next week, Instagram will test hiding the number of likes on a post from public view. Since the goal of many online trolls and users is to post whatever generates the most engagement with their account, not displaying this engagement metric should help prevent users from putting out inflammatory opinions for the sake of 'likes.' This article relates to this week's topic of Digital Discourse because it gives an example of a front-running social media company trying to return the state of digital discourse to productive as well as attempting to manage mental health issues that come with social media use.

### Class 11 - Current Tech Policy
[Andrew Yang wants you to make money off your data by making it your personal property](https://www.businessinsider.com/andrew-yang-data-ownership-property-right-policy-2019-11)

Media Justification: This article in Business Insider discusses new plans by presidential candidate, Andrew Yang, on regulating the tech industry. Yang hopes to establish regulation that makes personal data a property right, allowing consumers to make money when they let corporations use it. He also plans to make data collection and monetization a more transparent process so that people will be able to more easily understand what they are losing when companies harvest data freely. More specific policy plans Yang included in his recent blog post include: create a government agency to help with the health effects of technology (for kids), tax digital ads and regulate bot activity, and create new policy that specifically addresses companies that act between publishers and platforms like Youtube and Facebook. This article relates to this week's topic of Current Tech Policy because it provides an example of a presidential candidate addressing a number of current issues in technology use in specific ways. 
